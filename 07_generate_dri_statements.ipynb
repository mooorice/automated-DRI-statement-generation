{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embedded data with similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/06_LLM_data/full_merged_data.csv')\n",
    "# rename main similarity score to similarity_score_0\n",
    "df['similarity_score_0'] = df['similarity_score']\n",
    "df.drop('similarity_score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set lists for medium according to political alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rechts = ['WEWO', 'WEW', 'WDAY', 'NZZO']\n",
    "rechtsliberal = ['NZZS', 'NZZ', 'SAW']\n",
    "mitte = ['LUZ', 'ZWAS', 'ZWAO', 'ZWA', 'ZWSO', 'ZWAF', 'SRFA', 'SRF', 'SRFV', 'AZO', 'AZM', 'RTS', 'RTSV']\n",
    "linksliberal = ['BAZ', 'NNBS', 'TLM', 'TLMD', 'HEU', 'NNHEU', 'TDG', 'NNTDG', 'BZ', 'NNBE', 'BLI', 'BLIO', 'NNTA', 'TA', 'TAZT', 'NNTA', 'TPS', 'TPSO', 'TAS', 'TLMD', 'BLI', 'BLIO']\n",
    "links = ['WOZ', 'SBLI']\n",
    "\n",
    "medium_groups = {\n",
    "    'rechts': rechts,\n",
    "    'rechtsliberal': rechtsliberal,\n",
    "    'mitte': mitte,\n",
    "    'linksliberal': linksliberal,\n",
    "    'links': links\n",
    "}\n",
    "similarity_columns = [\n",
    "    'similarity_score_0', 'similarity_score_1', 'similarity_score_2',\n",
    "    'similarity_score_3', 'similarity_score_4', 'similarity_score_5',\n",
    "    'similarity_score_6', 'similarity_score_7'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Top scoring 'text' element per similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each group in the dictionary\n",
    "for group_name, group_list in medium_groups.items():\n",
    "    # Assuming df_selected is your DataFrame, and you have a 'text' column for each row\n",
    "\n",
    "    # Create an empty DataFrame to store the top 500 results for each column\n",
    "    top_500_all_scores = pd.DataFrame()\n",
    "\n",
    "    # Filter the DataFrame for the current group\n",
    "    df_selected = df[df['medium_code'].isin(group_list)]\n",
    "\n",
    "    # Dictionary to store top 500 rows for each similarity score column\n",
    "    top_500_dict = {}\n",
    "\n",
    "    # Iterate over each similarity score column\n",
    "    for col in similarity_columns:\n",
    "        # Sort by the similarity score column in descending order and select top 500 rows\n",
    "        top_500 = df_selected.sort_values(by=col, ascending=False).head(500)\n",
    "\n",
    "        # Add the top 500 rows to the dictionary with the column name as the key\n",
    "        top_500_dict[col] = top_500['text'].reset_index(drop=True)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    top_500_all_scores = pd.DataFrame(top_500_dict)\n",
    "\n",
    "    # Save the top 500 elements for each column to a CSV file, using the group name\n",
    "    top_500_all_scores.to_csv(f'data/06_LLM_data/inputs/{group_name}_top_500_similarity_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Consideration Statements with GPT for each similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate OpenAI Client\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Assistant\n",
    "### (We only need to do this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store\n",
    "vector_store = client.beta.vector_stores.create(name=\"DRI_Examples\")\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"data/06_LLM_data/similarity_scores/dri_example_statements.txt\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "vector_store_id = vector_store.id\n",
    "\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"DRI Considerations Assistant\"\n",
    "\n",
    "instructions = f\"\"\"\n",
    "You are an expert political Scientist. Your task is to find\n",
    "Consideration Statements for a DRI Survey on health costs in Switzerland from\n",
    "different media outlets grouped by political leaning on several subtopics.\n",
    "The following is a short introduction to the concept of DRI:\n",
    "\n",
    "\"\n",
    "The Deliberative Reason Index (DRI) is a tool used to measure the quality and\n",
    "improvement of group reasoning during deliberative processes. It focuses on\n",
    "evaluating reasoning at the group level, rather than individual level, emphasizing\n",
    "how group members collectively construct an understanding of an issue and agree\n",
    "on the terms of reasonableness.\n",
    "\n",
    "Consideration statements are specific statements in a survey designed to capture\n",
    "participants' opinions or evaluations of relevant factors, arguments, or aspects\n",
    "of an issue under discussion. These statements reflect the various interests,\n",
    "values, beliefs, or facts that participants consider important when reasoning\n",
    "about the issue.\n",
    "\n",
    "In the context of the Deliberative Reason Index (DRI), consideration statements\n",
    "help identify the range of viewpoints or concerns that individuals bring to a\n",
    "deliberative process. They serve as a way to assess how participants weigh\n",
    "different aspects of an issue before arriving at preferences for actions or policies.\n",
    "\"\n",
    "\n",
    "Consideration statements are typically concisely formulated and express a single\n",
    "premise for an argument or viewpoint. They are designed to capture the essence of\n",
    "a particular consideration that participants may have when discussing a given topic.\n",
    "Good consideration statements are clear, specific, and relevant to the issue at hand.\n",
    "They should not include demands for policy actions or express preferences for\n",
    "specific outcomes.\n",
    "\n",
    "Good examples include:\n",
    "- \"Private solutions are more efficient than government intervention in managing healthcare costs.\"\n",
    "- \"A growing older population is leading to higher utilization of healthcare services, increasing overall costs.\"\n",
    "- \"There is a significant lack of financial incentives for health prevention in Switzerland, leading to spiraling healthcare costs.\"ArithmeticError\n",
    "\n",
    "Bad examples include:\n",
    "- \"Introducing a unified health insurance system could reduce costs by decreasing expenditures on marketing, administrative fees, and high management salaries currently spread across multiple insurance companies.\"\n",
    "- \"We need to introduce cost targets in the health system to manage the rapid growth of healthcare costs.\"\n",
    "- \"Closing underutilized hospitals in Switzerland would result in significant cost savings and improve overall efficiency in health service delivery.\"\n",
    "\n",
    "Additionally read through the dri_example_statements.csv and familiarize yourself with the\n",
    "semantic structure of consideration statements.\n",
    "Be prepared to produce a list of the top 5 Consideration statements in JSON Format, based\n",
    "on the media outlets that will be procided to you.\n",
    "When prompted, make sure to produce all statements in English and in close semantic\n",
    "similarity to the examples. Do not include anything but a list of statements in\n",
    "JSON Format in your responses\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=name,\n",
    "    instructions=instructions,\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "asssistant_id = assistant.id\n",
    "\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt the Assistant\n",
    "### (Do this every run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_prompt(political_leaning, similarity_score):\n",
    "    # Define a dictionary mapping similarity scores to corresponding prompts\n",
    "    similarity_prompts = {\n",
    "        0: \"\"\"\n",
    "        Focus specifically on the topic of health costs in Switzerland.\n",
    "        \"\"\",\n",
    "        1: \"\"\"\n",
    "        Focus specifically on the topic of the health system of Switzerland and non-incremental policy reforms.\n",
    "        \"\"\",\n",
    "        2: \"\"\"\n",
    "        Focus specifically on the topic of Increasing utilisation of healthcare services per person.\n",
    "        \"\"\",\n",
    "        3: \"\"\"\n",
    "        Focus specifically on the topic of hospital planning and financing.\n",
    "        \"\"\",\n",
    "        4: \"\"\"\n",
    "        Focus specifically on the topic of the design/configuration/organisation of compulsory health insurance.\n",
    "        \"\"\",\n",
    "        5: \"\"\"\n",
    "        Focus specifically on the topic of a lack of incentives for health prevention.\n",
    "        \"\"\",\n",
    "        6: \"\"\"\n",
    "        Focus specifically on the topic of the coordination of health services.\n",
    "        \"\"\",\n",
    "        7: \"\"\"\n",
    "        Focus specifically on the topic of the financial burden of health costs on households (costs distribution).\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # Retrieve the correct prompt based on the similarity score\n",
    "    prompt_similarity = similarity_prompts.get(similarity_score, similarity_prompts[0])\n",
    "\n",
    "    # Final prompt creation with the selected prompt similarity\n",
    "    prompt = f\"\"\"\n",
    "        Create a list of 5 consideration statements for a DRI Survey on health costs in\n",
    "        Switzerland from the media outlets provided below. All media outlets provided come from\n",
    "        {political_leaning}-leaning media outlets. Make sure to do justice to the\n",
    "        perspectives and opinions described in the media outlets. The statements should be\n",
    "        in close semantic similarity to the examples provided in the dri_example_statements.csv\n",
    "        file but the content should be representative of the political opinion of the media outlets.\n",
    "        Make sure to capture the whole range of viewpoints and concerns that is represented in\n",
    "        the media outlets. Then boil it down to the top 5 most important consideration statements.\n",
    "        Consideration statements are typically concisely formulated and express a single\n",
    "        premise for an argument or viewpoint. They are designed to capture the essence of\n",
    "        a particular consideration that participants may have when discussing a given topic.\n",
    "\n",
    "        {prompt_similarity}\n",
    "\n",
    "        Format your response as a list of consideration statements in JSON format.\n",
    "        Make sure not to include anything else but the JSON object in your response.\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consideration_statements(political_leaning, similarity_score_list):\n",
    "    statements_df = pd.DataFrame(index=range(10))\n",
    "\n",
    "    for similarity_score in similarity_score_list:\n",
    "        # Path to the directory containing your CSV files\n",
    "        csv_path = f'data/06_LLM_data/input_data/{political_leaning}_top_500_similarity_scores.csv'\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(\"df loaded with shape:\")\n",
    "        print(df.shape)\n",
    "\n",
    "        txt_file_path = f'data/06_LLM_data/input_data/{political_leaning}_top_500_similarity_score_{similarity_score}.txt'\n",
    "\n",
    "        # Save the column as a text file, each value on a new line\n",
    "        df[f'similarity_score_{similarity_score}'].to_csv(txt_file_path, index=False, header=False)\n",
    "        print(f\"File {txt_file_path} has been created with content:\")\n",
    "        print(df[f'similarity_score_{similarity_score}'].head())\n",
    "\n",
    "        message_file = client.files.create(\n",
    "        file=open(txt_file_path, \"rb\"),\n",
    "        purpose=\"assistants\"\n",
    "        )\n",
    "        print(\"message_file:\")\n",
    "        print(message_file)\n",
    "\n",
    "        # Create a thread and attach the file to the message\n",
    "        thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": customize_prompt(political_leaning, similarity_score),\n",
    "            # Attach the new file to the message.\n",
    "            \"attachments\": [\n",
    "                { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "            ],\n",
    "            }\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        if os.path.exists(txt_file_path):\n",
    "            os.remove(txt_file_path)\n",
    "            print(f\"File {txt_file_path} has been removed.\")\n",
    "        else:\n",
    "            print(f\"File {txt_file_path} does not exist.\")\n",
    "\n",
    "        print(\"Waiting for the assistant to generate the consideration statements...\")\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id, assistant_id=assistant.id\n",
    "        )\n",
    "\n",
    "        messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "        print(\"messages:\")\n",
    "        print(messages)\n",
    "\n",
    "        message_content = messages[0].content[0].text.value\n",
    "\n",
    "        # Remove the markdown ```json``` block and newlines using regex\n",
    "        cleaned_content = re.sub(r'```json|```', '', message_content).strip()\n",
    "\n",
    "        # Load the cleaned content as a JSON array\n",
    "        statements = json.loads(cleaned_content)\n",
    "\n",
    "        # Create the column name dynamically\n",
    "        column_name = f\"Statements, similarity_score_{similarity_score}\"\n",
    "\n",
    "        # Pad the list of statements with NaN to match the length of the DataFrame\n",
    "        padded_statements = statements + [None] * (len(statements_df) - len(statements))\n",
    "\n",
    "        # Add the new column to the DataFrame\n",
    "        statements_df[column_name] = padded_statements\n",
    "\n",
    "        # Wait for 20 seconds before continuing to the next iteration to avoid rate limiting\n",
    "        print(f\"Waiting for 20 seconds before the next iteration...\")\n",
    "        time.sleep(20)\n",
    "\n",
    "\n",
    "    return statements_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Generation of DRI Statements\n",
    "\n",
    "# Define the political leaning and similarity score\n",
    "political_leaning_list = ['right', 'right-liberal', 'centrist', 'left-liberal', 'left']\n",
    "political_leaning= political_leaning_list[0]\n",
    "\n",
    "similarity_score_list = [i for i in range(8)]\n",
    "\n",
    "# Define vector store and assistant IDs if not already defined\n",
    "vector_store_id = ''\n",
    "asssistant_id = ''\n",
    "\n",
    "df = get_consideration_statements(political_leaning, similarity_score_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "df.to_csv('data/06_LLM_data/outputs/consideration_statements/centrist_consideration_statements.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Policy Preferences with GPT for each similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate OpenAI Client\n",
    "\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Assistant\n",
    "### (We only need to do this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store\n",
    "vector_store = client.beta.vector_stores.create(name=\"DRI_policy_options\")\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"data/06_LLM_data/similarity_scores/dri_example_policy_options.txt\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "vector_store_id = vector_store.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"DRI Policy Assistant\"\n",
    "\n",
    "instructions = f\"\"\"\n",
    "You are an expert political Scientist. Your task is to find\n",
    "Policy Options for a DRI Survey on health costs in Switzerland from\n",
    "different media outlets grouped by political leaning on several subtopics.\n",
    "The following is a short introduction to the concept of DRI:\n",
    "\n",
    "\"\n",
    "The Deliberative Reason Index (DRI) is a tool used to measure the quality and\n",
    "improvement of group reasoning during deliberative processes. It focuses on\n",
    "evaluating reasoning at the group level, rather than individual level, emphasizing\n",
    "how group members collectively construct an understanding of an issue and agree\n",
    "on the terms of reasonableness.\n",
    "\n",
    "Policy Options are specific possible actions or strategies that will be ranked\n",
    "by preferance within the DRI survey. These options reflect the various policy changes\n",
    "that are discussed in the public discourse on to the issue at hand.\n",
    "\n",
    "In the context of the Deliberative Reason Index (DRI), policy options\n",
    "help identify the range of preferences and opinions concerning policy demands\n",
    "that individuals bring to a deliberative process.\n",
    "\"\n",
    "\n",
    "Policy options are typically concisely formulated and express a single\n",
    "strategy or action. They are designed to capture the main solutions discussed\n",
    "within the public media discourse on a given topic.\n",
    "Good policy options are clear, specific, and relevant to the issue at hand.\n",
    "They should include demands for policy actions and express preferences for\n",
    "specific outcomes. They can include a statement of the problem if necessary.\n",
    "\n",
    "Additionally read through the dri_example_policy_options.csv and familiarize yourself with the\n",
    "semantic structure of consideration statements.\n",
    "Be prepared to produce a list of the top policy options in JSON Format, based\n",
    "on the media outlets that will be procided to you.\n",
    "When prompted, make sure to produce all statements in English and in close semantic\n",
    "similarity to the examples. Do not include anything but a list of statements in\n",
    "JSON Format in your responses\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=name,\n",
    "    instructions=instructions,\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "asssistant_id = assistant.id\n",
    "\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt the Assistant\n",
    "### (Do this every run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_prompt(political_leaning):\n",
    "    # Define a dictionary mapping similarity scores to corresponding prompts\n",
    "\n",
    "    # Final prompt creation with the selected prompt similarity\n",
    "    prompt = f\"\"\"\n",
    "        Create a list of policy options for a DRI Survey on health costs in\n",
    "        Switzerland from the media outlets provided below. All media outlets provided come from\n",
    "        {political_leaning}-leaning media outlets. Make sure to do justice to the\n",
    "        perspectives and opinions described in the media outlets. The statements should be\n",
    "        in close semantic similarity to the examples provided in the dri_example_policy_options.csv\n",
    "        file but the content should be representative of the political opinion of the media outlets.\n",
    "        Make sure to capture the whole range of policy proposals that is represented in\n",
    "        the media outlets. Then boil it down to the top 5 most important policy options.\n",
    "        Policy options are typically concisely formulated and express a single\n",
    "        action or strategy to a give issue.\n",
    "\n",
    "        Format your response as a list of consideration statements in JSON format.\n",
    "        Make sure not to include anything else but the JSON object in your response.\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consideration_statements(political_leaning):\n",
    "    policies_df = pd.DataFrame(index=range(10))\n",
    "\n",
    "    # Path to the directory containing your CSV files\n",
    "    csv_path = f'data/06_LLM_data/input_data/{political_leaning}_top_500_similarity_scores.csv'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"df loaded with shape:\")\n",
    "    print(df.shape)\n",
    "\n",
    "    txt_file_path = f'data/06_LLM_data/input_data/{political_leaning}_top_500_similarity_score.txt'\n",
    "\n",
    "    # Save the column as a text file, each value on a new line\n",
    "    df.to_csv(txt_file_path, index=False, header=False)\n",
    "    print(f\"File {txt_file_path} has been created\")\n",
    "\n",
    "    message_file = client.files.create(\n",
    "    file=open(txt_file_path, \"rb\"),\n",
    "    purpose=\"assistants\"\n",
    "    )\n",
    "    print(\"message_file:\")\n",
    "    print(message_file)\n",
    "\n",
    "    # Create a thread and attach the file to the message\n",
    "    thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": customize_prompt(political_leaning),\n",
    "        # Attach the new file to the message.\n",
    "        \"attachments\": [\n",
    "            { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "        ],\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    if os.path.exists(txt_file_path):\n",
    "        # os.remove(txt_file_path)\n",
    "        print(f\"File {txt_file_path} has been removed.\")\n",
    "    else:\n",
    "        print(f\"File {txt_file_path} does not exist.\")\n",
    "\n",
    "    print(\"Waiting for the assistant to generate the policy options...\")\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id, assistant_id=assistant.id\n",
    "    )\n",
    "\n",
    "    messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "    print(\"messages:\")\n",
    "    print(messages)\n",
    "\n",
    "    message_content = messages[0].content[0].text.value\n",
    "\n",
    "    # Remove the markdown ```json``` block and newlines using regex\n",
    "    cleaned_content = re.sub(r'```json|```', '', message_content).strip()\n",
    "\n",
    "    # Now you can load the cleaned content as a JSON array\n",
    "    statements = json.loads(cleaned_content)\n",
    "\n",
    "    # Create the column\n",
    "    column_name = f\"Statements, similarity_score\"\n",
    "\n",
    "    # Pad the list of statements with NaN to match the length of the DataFrame\n",
    "    padded_statements = statements + [None] * (len(policies_df) - len(statements))\n",
    "\n",
    "    # Add the new column to the DataFrame\n",
    "    policies_df[column_name] = padded_statements\n",
    "\n",
    "\n",
    "    return policies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Generation of DRI Statements\n",
    "\n",
    "# Define the political leaning and similarity score\n",
    "political_leaning_list = ['right', 'right-liberal', 'centrist', 'left-liberal', 'left']\n",
    "political_leaning= political_leaning_list[0]\n",
    "\n",
    "similarity_score_list = [i for i in range(8)]\n",
    "\n",
    "# Define vector store and assistant IDs if not already defined\n",
    "vector_store_id = ''\n",
    "asssistant_id = ''\n",
    "\n",
    "df = get_consideration_statements(political_leaning_list[4])\n",
    "\n",
    "# Rename accordingly\n",
    "df_left = df\n",
    "# df_leftliberal = df\n",
    "# df_centrist = df\n",
    "# df_rightliberal = df\n",
    "# df_right = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged DFs\n",
    "merged_df = pd.concat([df_right, df_rightliberal, df_centrist,\n",
    "                       df_leftliberal, df_left], axis=1)\n",
    "\n",
    "# Clean DF\n",
    "df_cleaned = merged_df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF\n",
    "df_cleaned.to_csv('data/06_LLM_data/outputs/policy_options/policy_preferences.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
