{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Set pandas options to display full text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & format data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data dictionary\n",
    "data = {\n",
    "    \"REALITY OF CHANGE\": [\n",
    "        \"Q10_1 Climate variation is normal, so why should this be a problem?\",\n",
    "        \"Q10_2 Climate change will not be a problem because there will be technological solutions available.\",\n",
    "        \"Q10_3 I think it is safe to say climate change is here.\",\n",
    "        \"Q10_4 The negative effects of climate change on local commerce should be taken into account.\",\n",
    "        \"Q10_5 I do not trust what scientists say about climate change.\",\n",
    "        \"Q10_6 I do not trust what I hear about climate change from the government.\",\n",
    "        \"Q10_7 It is difficult to trust what comes out in the media on the issue of climate change.\",\n",
    "        \"Q10_8 There is not enough information to definitively say that climate change is real.\"\n",
    "    ],\n",
    "    \"RESPONSABILITY OF ACTION\": [\n",
    "        \"Q20_1 There is not much point in me doing anything to make agriculture more sustainable. No one else is going to.\",\n",
    "        \"Q20_2 I do not know what to do. I am very concerned and would like to do something, but I don’t have a realistic shortlist of things that would really make a difference.\",\n",
    "        \"Q20_3 I believe that the difference we can have as an individual, in Switzerland, is so minimal that our actions are worthless.\",\n",
    "        \"Q20_4 I am not going to do anything to address the impacts of the agri-food system because it is not a major issue.\"\n",
    "    ],\n",
    "    \"ECONOMY AND MARKETS\": [\n",
    "        \"Q30_1 I am happy to pay a higher price for local or organic food products\",\n",
    "        \"Q30_2 Eating sustainably is too expensive, and only wealthy people can afford it\",\n",
    "        \"Q30_3 Agricultural subsidies should promote sustainable, pesticide and antibiotic-free production.\",\n",
    "        \"Q30_4 Sustainable agriculture increases prices and harms consumer freedom. The production should be adapted to what people demand.\",\n",
    "        \"Q30_5 Food accessibility (price) and security (availability) is NOT COMPATIBLE with a sustainable food system\",\n",
    "        \"Q30_6 Strong regulation of food production will eventually damage our economic relationship with other countries\",\n",
    "        \"Q30_7 We should develop short distribution channels and support local production instead of supporting big agrifood corporations\",\n",
    "        \"Q30_8 We need to focus on adaptation actions that are concerned with the economic future of the country.\"\n",
    "    ],\n",
    "    \"POLLUTION AND BIODIVERSITY\": [\n",
    "        \"Q40_1 Actions on the food system in Switzerland will lead to increased imports and a shift of pollution abroad\",\n",
    "        \"Q40_2 We need actions to protect inhabitants and biodiversity from harmful pesticides.\",\n",
    "        \"Q40_3 As long as we use animals in agriculture, it cannot be sustainable\",\n",
    "        \"Q40_4 We need to deal with the water pollution issue through measures such as reducing fertilizer and pesticide use.\"\n",
    "    ],\n",
    "    \"SUSTAINABLE AGRICULTURE\": [\n",
    "        \"Q50_1 Banning pesticides might help the local biodiversity but decreases our food production capacity and autonomy\",\n",
    "        \"Q50_2 Agriculture is already very sustainable. Swiss farmers are on the right track\",\n",
    "        \"Q50_3 Intensive food production can go along with the protection of the environment and health\",\n",
    "        \"Q50_4 Farmers already suffer enough from strict rules and paperwork. Family farmers should have more liberties\",\n",
    "        \"Q50_5 The main focus of planning for adaptation should be to prepare the food system for extreme weather events, such as drought and flooding.\",\n",
    "        \"Q50_6 Products that use environmentally harmful ingredients, such as palm oil, should be taxed in the same way as tobacco products.\",\n",
    "        \"Q50_7 If Switzerland reduces greenhouse gas emissions in its food system, it won’t make a difference.\"\n",
    "    ],\n",
    "    \"GLOBAL PERSPECTIVE\": [\n",
    "        \"Q60_1 It is important to plan for migration by people displaced by malnutrition and famine.\",\n",
    "        \"Q60_2 We should focus on protecting human systems rather than environmental ecosystems.\",\n",
    "        \"Q60_3 The Swiss food system depends on imports from other countries, and it is in our interest to help find an effective global solution.\",\n",
    "        \"Q60_4 Some communities are more affected than others by the global agri-food system, but this is not a priority issue.\",\n",
    "        \"Q60_5 The Swiss food system is particularly vulnerable to climate change, and it is in our interest to help find an effective global solution.\",\n",
    "        \"Q60_6 Climate warming will ultimately benefit food production globally as plants better growth in higher temperature\"\n",
    "    ],\n",
    "    \"ACTION AND RESPONSES\": [\n",
    "        \"Q70_1 It is NOT necessary to engage with the community when deciding what are the most important issues for planning for food system changes.\",\n",
    "        \"Q70_2 Planning for food system adaptation needs a holistic approach, considering a whole range of issues, instead of focusing on individual issues.\",\n",
    "        \"Q70_3 There is no urgent need to prepare for an increase in illness and death caused by intensive use of pesticides/antibiotics\",\n",
    "        \"Q70_4 The community should be involved in discussions about food system adaptation.\",\n",
    "        \"Q70_5 It is important to support small-land local farming as they have the fewest resources to deal with the impacts of climate change.\"\n",
    "    ],\n",
    "    \"PREFERENCES\": [\n",
    "        \"Q90_1 Leave the policy settings as they are.\",\n",
    "        \"Q90_2 Policies that emphasise fewer regulations (e.g., policies that promote free trade agreements by reducing food regulation)\",\n",
    "        \"Q90_3 Policies that involve moderate sustainable regulations (e.g., banning certain types of pesticides, incentivising organic agriculture)\",\n",
    "        \"Q90_4 Policies that involve a radical sustainable food regulation (e.g., banning all pesticides, banning the importation of food-related products that employ non-sustainable approaches, exclusively incentivising organic agriculture)\",\n",
    "        \"Q90_5 Policies that create incentives for local producers to produce sustainable food (e.g., subsidies or tax breaks for local farmers who produce organic products)\",\n",
    "        \"Q90_6 Adaptation policies and expenditure. Planning controls and emergency response programs.\",\n",
    "        \"Q90_7 Preparing for climate risk for food production through the development of new approaches and technologies that enhance resilience to the impacts of climate variability or change.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Reshaping the data into a new DataFrame\n",
    "reshaped_data = []\n",
    "\n",
    "for category, questions in data.items():\n",
    "    for question in questions:\n",
    "        if question:  # Check if question is not None\n",
    "            question_id, question_text = question.split(\" \", 1)\n",
    "            reshaped_data.append({\n",
    "                \"Qid\": question_id,\n",
    "                \"category\": category,\n",
    "                \"statement\": question_text\n",
    "            })\n",
    "\n",
    "validation_df = pd.DataFrame(reshaped_data)\n",
    "\n",
    "# Adding a new column 'category #' by extracting the first digit after 'Q'\n",
    "validation_df['category #'] = validation_df['Qid'].str.extract(r'Q(\\d)').astype(int)\n",
    "\n",
    "# Filtering rows where 'category #' is between 1 and 7\n",
    "validation_df = validation_df[validation_df['category #'].between(1, 9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preferences DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_preferences(preferences_df):\n",
    "    \"\"\"\n",
    "    Transforms a wide-format DataFrame into a long-format DataFrame with\n",
    "    columns for 'statement' and 'political leaning'.\n",
    "    Drops rows where 'statement' is NaN.\n",
    "\n",
    "    Parameters:\n",
    "        preferences_df (pd.DataFrame): Input DataFrame with political preferences.\n",
    "        political_leaning (str): A single political leaning label for all rows.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame.\n",
    "    \"\"\"\n",
    "    # Melt the DataFrame to long format\n",
    "    melted_df = preferences_df.melt(var_name=\"political leaning\",\n",
    "                                    value_name=\"statement\",\n",
    "                                    ignore_index=False)\n",
    "\n",
    "    # Drop rows where 'statement' is NaN\n",
    "    melted_df = melted_df.dropna(subset=[\"statement\"])\n",
    "\n",
    "    # Reset the index for a clean DataFrame\n",
    "    melted_df = melted_df.reset_index(drop=True)\n",
    "\n",
    "    return melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferences_df = pd.read_csv('data/05_LLM_data/outputs/policy_options/policy_preferences.csv')\n",
    "preferences_df = transform_preferences(preferences_df,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statements DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_statements(input_csv, political_leaning):\n",
    "    \"\"\"\n",
    "    Transforms a wide CSV format into a long format DataFrame with\n",
    "    columns for 'statement', 'similarity_score_id', and 'political leaning'.\n",
    "    Drops rows where 'statement' is NaN.\n",
    "\n",
    "    Parameters:\n",
    "        input_csv (str): Path to the input CSV file.\n",
    "        political_leaning (str): A single political leaning label for all rows.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Melt the DataFrame to long format\n",
    "    melted_df = df.melt(var_name=\"similarity_score\",\n",
    "                        value_name=\"statement\",\n",
    "                        ignore_index=False)\n",
    "\n",
    "    # Extract the similarity_score_id from the column name\n",
    "    melted_df[\"similarity score id\"] = melted_df[\"similarity_score\"].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "    # Assign the provided political leaning to all rows\n",
    "    melted_df[\"political leaning\"] = political_leaning\n",
    "\n",
    "    # Drop rows where 'statement' is NaN\n",
    "    melted_df = melted_df.dropna(subset=[\"statement\"])\n",
    "\n",
    "    # Drop the original similarity_score column\n",
    "    melted_df = melted_df.drop(columns=[\"similarity_score\"])\n",
    "\n",
    "    # Reset the index for a clean DataFrame\n",
    "    melted_df = melted_df.reset_index(drop=True)\n",
    "\n",
    "    return melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the political leanings and corresponding file paths\n",
    "political_leanings = [\"left\", \"left-liberal\", \"centrist\", \"right-liberal\", \"right\"]\n",
    "file_paths = [\n",
    "    'data/LLM_data/outputs/consideration_statements/left_consideration_statements.csv',\n",
    "    'data/LLM_data/outputs/consideration_statements/left-liberal_consideration_statements.csv',\n",
    "    'data/LLM_data/outputs/consideration_statements/centrist_consideration_statements.csv',\n",
    "    'data/LLM_data/outputs/consideration_statements/right-liberal_consideration_statements.csv',\n",
    "    'data/LLM_data/outputs/consideration_statements/right_consideration_statements.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "all_statements = []\n",
    "\n",
    "# Loop through each file and political leaning, transforming the data\n",
    "for political_leaning, file_path in zip(political_leanings, file_paths):\n",
    "    transformed_df = transform_statements(file_path, political_leaning)\n",
    "    all_statements.append(transformed_df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "statements_df = pd.concat(all_statements, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed statements\n",
    "def embed_statements(df, model, column_name='statement'):\n",
    "    \"\"\"\n",
    "    Embeds the text in the specified column using the given model.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing the text data.\n",
    "        model (SentenceTransformer): The preloaded SentenceTransformer model.\n",
    "        column_name (str): The column containing the text to embed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input DataFrame with an added 'embedding' column.\n",
    "    \"\"\"\n",
    "    print(f\"Embedding {len(df)} statements from column '{column_name}'...\")\n",
    "    # Ensure all entries in the specified column are strings and handle NaN values\n",
    "    df[column_name] = df[column_name].astype(str).fillna('')\n",
    "\n",
    "    # Encode the text column into embeddings\n",
    "    embeddings = model.encode(df[column_name].tolist(), batch_size=32, convert_to_tensor=True)\n",
    "    df['embedding'] = embeddings.tolist()\n",
    "\n",
    "    print(\"Embedding completed for this DataFrame.\")\n",
    "    return df\n",
    "\n",
    "# Model name and initialization\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "print(\"Loading embeddings model...\")\n",
    "model = SentenceTransformer(model_name, device='cpu')  # Use 'cuda' if GPU is available\n",
    "\n",
    "# Embed statements in each DataFrame\n",
    "preferences_df = embed_statements(preferences_df, model)\n",
    "statements_df = embed_statements(statements_df, model)\n",
    "validation_df = embed_statements(validation_df, model)\n",
    "\n",
    "print(\"Embedding process completed for all DataFrames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate similarity scores between two sets of embeddings\n",
    "def calculate_similarity(source_df, target_df, source_column, target_column):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity scores between all elements of source_df[source_column]\n",
    "    and target_df[target_column].\n",
    "\n",
    "    Parameters:\n",
    "        source_df (pd.DataFrame): DataFrame containing source embeddings.\n",
    "        target_df (pd.DataFrame): DataFrame containing target embeddings.\n",
    "        source_column (str): Column name in source_df with embeddings.\n",
    "        target_column (str): Column name in target_df with embeddings.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with similarity scores.\n",
    "    \"\"\"\n",
    "    print(f\"Calculating similarity between {len(source_df)} source embeddings and {len(target_df)} target embeddings...\")\n",
    "\n",
    "    # Convert embeddings to tensors\n",
    "    source_embeddings = torch.tensor(source_df[source_column].tolist())\n",
    "    target_embeddings = torch.tensor(target_df[target_column].tolist())\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_scores = util.cos_sim(source_embeddings, target_embeddings)\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "# Filter validation_df based on categories\n",
    "validation_preferences = validation_df[validation_df['category #'] == 9]\n",
    "validation_statements = validation_df[validation_df['category #'] < 9]\n",
    "\n",
    "# Calculate similarity scores\n",
    "similarity_prefs_validation = calculate_similarity(\n",
    "    preferences_df, validation_preferences, source_column='embedding', target_column='embedding'\n",
    ")\n",
    "\n",
    "similarity_statements_validation = calculate_similarity(\n",
    "    statements_df, validation_statements, source_column='embedding', target_column='embedding'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_similarity(single_validation, source_df, source_column='embedding', target_column='embedding', text_column='statement', extra_validation_columns=None, extra_source_columns=None):\n",
    "    \"\"\"\n",
    "    Ranks all elements of source_df by similarity score to a single element from validation_df,\n",
    "    displaying the validation statement and source statements with similarity scores and additional columns.\n",
    "\n",
    "    Parameters:\n",
    "        single_validation (pd.Series): A single row from validation_df with the target embedding.\n",
    "        source_df (pd.DataFrame): DataFrame containing source embeddings to rank.\n",
    "        source_column (str): Column name in source_df with embeddings.\n",
    "        target_column (str): Column name in single_validation containing the embedding.\n",
    "        text_column (str): Column name in source_df and single_validation containing the statements.\n",
    "        extra_validation_columns (list): Additional columns from single_validation to display.\n",
    "        extra_source_columns (list): Additional columns from source_df to include in the result.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with similarity scores ranked in descending order, including source statements and extra columns.\n",
    "    \"\"\"\n",
    "    print(\"Calculating similarity for a single validation element...\")\n",
    "\n",
    "    # Extract the validation statement\n",
    "    validation_statement = single_validation[text_column]\n",
    "    print(f\"Validation Statement: {validation_statement}\\n\")\n",
    "\n",
    "    # Extract additional validation columns if provided\n",
    "    validation_data = {\n",
    "        col: single_validation[col] for col in extra_validation_columns if col in single_validation\n",
    "    }\n",
    "\n",
    "    # Convert the single validation embedding to a tensor\n",
    "    target_embedding = torch.tensor(single_validation[target_column])\n",
    "\n",
    "    # Convert source embeddings to tensors\n",
    "    source_embeddings = torch.tensor(source_df[source_column].tolist())\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_scores = util.cos_sim(target_embedding.unsqueeze(0), source_embeddings)\n",
    "\n",
    "    # Flatten similarity scores and create a DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'source_index': source_df.index.tolist(),  # Use the index as the identifier\n",
    "        'source_statement': source_df[text_column].tolist(),  # Include the source statements\n",
    "        'similarity_score': similarity_scores.squeeze(0).tolist()\n",
    "    })\n",
    "\n",
    "    # Add additional source columns if provided\n",
    "    if extra_source_columns:\n",
    "        for col in extra_source_columns:\n",
    "            if col in source_df:\n",
    "                result_df[col] = source_df[col].tolist()\n",
    "\n",
    "    # Sort by similarity score in descending order\n",
    "    result_df = result_df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"Ranking completed.\")\n",
    "    return validation_statement, validation_data, result_df\n",
    "\n",
    "\n",
    "def create_similarity_summary(validation_df, source_df, top_n=5, source_column='embedding', target_column='embedding', text_column='statement', extra_validation_columns=None, extra_source_columns=None):\n",
    "    \"\"\"\n",
    "    Creates a summary DataFrame containing the top N closest statements and their metadata for each validation statement.\n",
    "\n",
    "    Parameters:\n",
    "        validation_df (pd.DataFrame): DataFrame containing validation statements and embeddings.\n",
    "        source_df (pd.DataFrame): DataFrame containing source statements and embeddings.\n",
    "        top_n (int): Number of closest statements to include.\n",
    "        source_column (str): Column name in source_df with embeddings.\n",
    "        target_column (str): Column name in validation_df with embeddings.\n",
    "        text_column (str): Column name in source_df and validation_df containing the statements.\n",
    "        extra_validation_columns (list): Additional columns from validation_df to include in the result.\n",
    "        extra_source_columns (list): Additional columns from source_df to include in the result.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Summary DataFrame.\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "\n",
    "    for _, single_validation in validation_df.iterrows():\n",
    "        validation_statement, validation_data, ranked_statements = rank_by_similarity(\n",
    "            single_validation,\n",
    "            source_df,\n",
    "            source_column=source_column,\n",
    "            target_column=target_column,\n",
    "            text_column=text_column,\n",
    "            extra_validation_columns=extra_validation_columns,\n",
    "            extra_source_columns=extra_source_columns\n",
    "        )\n",
    "\n",
    "        top_results = ranked_statements.head(top_n)\n",
    "\n",
    "        summary_row = {\n",
    "            'Qid': validation_data.get('Qid', None),\n",
    "            'validation_statement': validation_statement\n",
    "        }\n",
    "\n",
    "        for i, row in top_results.iterrows():\n",
    "            summary_row[f'{i + 1}st_closest_statement'] = row['source_statement']\n",
    "            summary_row[f'{i + 1}st_closest_category'] = row.get('similarity score id', None)\n",
    "            summary_row[f'{i + 1}st_closest_political_leaning'] = row.get('political leaning', None)\n",
    "\n",
    "        summary_data.append(summary_row)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "\n",
    "# Generate summary DataFrame for validation_df against statements_df\n",
    "statements_similarity_summary = create_similarity_summary(\n",
    "    validation_df[:41],\n",
    "    statements_df,\n",
    "    top_n=5,\n",
    "    source_column='embedding',\n",
    "    target_column='embedding',\n",
    "    text_column='statement',\n",
    "    extra_validation_columns=['category #', 'Qid'],\n",
    "    extra_source_columns=['similarity score id', 'political leaning']\n",
    ")\n",
    "\n",
    "# Display the summary\n",
    "print(\"Similarity Summary:\")\n",
    "statements_similarity_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary DataFrame for validation_df against statements_df\n",
    "\n",
    "preferences_similarity_summary = create_similarity_summary(\n",
    "    validation_df[41:],\n",
    "    preferences_df,\n",
    "    top_n=5,\n",
    "    source_column='embedding',\n",
    "    target_column='embedding',\n",
    "    text_column='statement',\n",
    "    extra_validation_columns=['category #', 'Qid'],\n",
    "    extra_source_columns=['similarity score id', 'political leaning']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_similarity_summary.to_csv('data/06_comparison/statements_similarity_summary.csv', index=False)\n",
    "preferences_similarity_summary.to_csv('data/06_comparison/preferences_similarity_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
