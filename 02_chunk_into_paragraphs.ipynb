{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lzma\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the .tsv.xz file\n",
    "compressed_file_path = \"data/00_downloads/dataset.tsv.xz\"\n",
    "\n",
    "# Extract and read the .tsv.xz file directly into a pandas DataFrame\n",
    "with lzma.open(compressed_file_path) as file:\n",
    "    df = pd.read_csv(file, delimiter='\\t')\n",
    "\n",
    "df_unique = df.drop_duplicates(subset=['content_id'], keep='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the relevant columns\n",
    "text_column = df_unique['content']\n",
    "id_column = df_unique['id']\n",
    "medium_code_column = df_unique['medium_code']\n",
    "doctype_column = df_unique['doctype']\n",
    "language_column = df_unique['language']\n",
    "head_column = df_unique['head']\n",
    "\n",
    "# Step 2: Function to extract paragraphs from the text\n",
    "def extract_paragraphs(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    return [p.get_text() for p in paragraphs]\n",
    "\n",
    "# Step 3: Apply the function to each row and create chunks\n",
    "df_unique['text'] = text_column.apply(extract_paragraphs)\n",
    "\n",
    "# Step 4: Flatten the list of paragraphs and add the original 'id' as a column\n",
    "all_paragraphs = []\n",
    "ids = []\n",
    "medium_codes = []\n",
    "doctypes = []\n",
    "languages = []\n",
    "heads = []\n",
    "\n",
    "for original_id, medium_code, doctype, language, head, paragraph_list in zip(id_column,\n",
    "                                                                             medium_code_column,\n",
    "                                                                             doctype_column,\n",
    "                                                                             language_column,\n",
    "                                                                             head_column,\n",
    "                                                                             df_unique['text']):\n",
    "    for paragraph in paragraph_list:\n",
    "        all_paragraphs.append(paragraph)\n",
    "        ids.append(original_id)\n",
    "        medium_codes.append(medium_code)\n",
    "        doctypes.append(doctype)\n",
    "        languages.append(language)\n",
    "        heads.append(head)\n",
    "\n",
    "# Step 5: Create a DataFrame for the Paragraphs Dataset\n",
    "df_paragraphs = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'text': all_paragraphs,\n",
    "    'medium_code': medium_codes,\n",
    "    'doctype': doctypes,\n",
    "    'language': languages,\n",
    "    'head': heads\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Paragraphs that don't include one of our keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords\n",
    "keywords = [\n",
    "    \"Gesundheitskosten\",\n",
    "    \"Gesundheitssystem\",\n",
    "    \"Gesundheitswesen\",\n",
    "    \"Gesundheitspolitik\",\n",
    "    \"Gesundheitsreform\",\n",
    "    \"Gesundheitssektor\",\n",
    "    \"Gesundheitsversorgung\",\n",
    "    \"Spitalwesen\",\n",
    "    \"Versicherungspflicht\",\n",
    "    \"versicherungsmodell\",\n",
    "    \"Krankenkassen\",\n",
    "    \"Krankenversicherung\",\n",
    "    \"Krankenhaus\",\n",
    "    \"Spital\",\n",
    "    \"Gesundheistprävention\",\n",
    "    \"Gesundheitsförderung\",\n",
    "    \"Gesundheitsdienste\",\n",
    "    \"Coûts de la santé\",\n",
    "    \"Système de santé\",\n",
    "    \"Politique de santé\",\n",
    "    \"Secteur de la santé\",\n",
    "    \"Réforme de la santé\",\n",
    "    \"Secteur sanitaire\",\n",
    "    \"Accès aux soins de santé\",\n",
    "    \"Secteur hospitalier\",\n",
    "    \"Obligation d'assurance\",\n",
    "    \"Modèle d'assurance\",\n",
    "    \"Caisses maladie\",\n",
    "    \"Assurance maladie\",\n",
    "    \"Hôpital\",\n",
    "    \"Centre hospitalier\",\n",
    "    \"Prévention sanitaire\",\n",
    "    \"Promotion de la santé\",\n",
    "    \"Services de santé\",\n",
    "    \"Costi della salute\",\n",
    "    \"Sistema sanitario\",\n",
    "    \"Settore sanitario\",\n",
    "    \"Politica sanitaria\",\n",
    "    \"Riforma sanitaria\",\n",
    "    \"Settore della salute\",\n",
    "    \"Accesso ai servizi sanitari\",\n",
    "    \"Settore ospedaliero\",\n",
    "    \"Obbligo di assicurazione\",\n",
    "    \"Modello assicurativo\",\n",
    "    \"Casse malati\",\n",
    "    \"Assicurazione malattia\",\n",
    "    \"Ospedale\",\n",
    "    \"Centro ospedaliero\",\n",
    "    \"Prevenzione sanitaria\",\n",
    "    \"Promozione della salute\",\n",
    "    \"Servizi sanitari\"\n",
    "]\n",
    "\n",
    "# Convert the list of keywords to a Pandas Series\n",
    "keywords_series = pd.Series(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_paragraphs\n",
    "\n",
    "# Function to normalize and remove accents\n",
    "def normalize(text):\n",
    "    if isinstance(text, str):  # Ensure the value is a string\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = text.encode('ASCII', 'ignore').decode('utf-8')\n",
    "        return text.lower()\n",
    "    return ''  # Return an empty string for non-string values\n",
    "\n",
    "\n",
    "# Normalize and convert the 'text' column\n",
    "df['text_normalized'] = df['text'].apply(normalize)\n",
    "\n",
    "# Normalize the keywords\n",
    "normalized_keywords = [normalize(keyword) for keyword in keywords]\n",
    "\n",
    "# Create a regex pattern for the keywords\n",
    "pattern = '|'.join(re.escape(keyword) for keyword in normalized_keywords)\n",
    "\n",
    "# Create a boolean mask where any normalized keyword is found in the normalized 'text' column\n",
    "mask = df['text_normalized'].str.contains(pattern, case=False, na=False)\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "filtered_df = df[mask]\n",
    "\n",
    "# Drop the normalized column\n",
    "filtered_df = filtered_df.drop(columns=['text_normalized'])\n",
    "\n",
    "# Create unique IDs for the filtered DataFrame\n",
    "filtered_df['unique_id'] = range(1, len(filtered_df) + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the paragraphs to a new CSV\n",
    "filtered_df.to_csv('data/01_text_data/paragraphs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
